{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael.781/Desktop/DataScience/venvMT/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import pprint\n",
    "# from transformers import MarianMTModel, MarianTokenizer\n",
    "# import whisper\n",
    "from faster_whisper import WhisperModel\n",
    "import ctranslate2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Podcasts/podcastsegmentfr.mp3\n"
     ]
    }
   ],
   "source": [
    "podcastfolder = \"./Podcasts\"\n",
    "podcastfiles = []\n",
    "for file in os.listdir(podcastfolder):\n",
    "    if file != \".DS_Store\":\n",
    "        podcastfiles.append(file)\n",
    "podcastaudio = podcastfolder + \"/\" + podcastfiles[0]\n",
    "print(podcastaudio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turbo_model = \"openai/whisper-large-v3-turbo\"\n",
    "# ct2_output_dir = \"whisper-large-v3-turbo-ct2\"\n",
    "\n",
    "# converter = ctranslate2.converters.TransformersConverter(\n",
    "#     model_name_or_path=turbo_model, copy_files=[\"tokenizer.json\", \"preprocessor_config.json\"]\n",
    "# )\n",
    "# converter.convert(output_dir=ct2_output_dir, quantization=\"int8\", force=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if ssl verification fails, go into python folder and run install certificates\n",
    "# baseline_model_name = \"turbo\"\n",
    "# baseline_model = whisper.load_model(baseline_model_name, device=\"cpu\")\n",
    "# result = baseline_model.transcribe(podcastaudio, beam_size=5, language=\"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint.pprint(result[\"text\"], width=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Mbrwn/whisper-turbo-ct2\"\n",
    "model = WhisperModel(model_name, device = \"cpu\", compute_type=\"int8\")\n",
    "segments, info = model.transcribe(podcastaudio, beam_size=5, language=\"fr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s -> 8.54s]  Sa capacité à fédérer, c'est-à-dire à faire en sorte que la population se réunisse et soit heureuse ensemble.\n",
      "[9.34s -> 16.08s]  La France a aussi pu montrer, grâce aux Jeux olympiques, sa capacité à construire des infrastructures,\n",
      "[16.08s -> 25.32s]  donc des bâtiments de qualité, à accueillir le tourisme et à organiser en général un des événements les plus importants du monde.\n",
      "[25.60s -> 28.46s]  Voilà, donc ça c'est pour la partie un peu logistique.\n",
      "[28.46s -> 33.50s]  Et maintenant, si on s'intéresse plus particulièrement aux performances sportives,\n",
      "[34.22s -> 37.52s]  la France avait un objectif assez clair pour ces Jeux olympiques.\n",
      "[38.00s -> 43.72s]  On voulait faire partie du top 5 des nations au classement des médailles.\n",
      "[43.72s -> 52.84s]  Autrement dit, être dans les 5 premiers pays en ce qui concerne le nombre de médailles et plus particulièrement les médailles d'or.\n",
      "[52.84s -> 59.12s]  Et Cocorico, on a réussi, puisque la France a remporté 64.\n"
     ]
    }
   ],
   "source": [
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt_model_name = \"Helsinki-NLP/opus-mt-fr-en\"\n",
    "# tokenizer = MarianTokenizer.from_pretrained(mt_model_name)\n",
    "# mt_model = MarianMTModel.from_pretrained(mt_model_name)\n",
    "\n",
    "\n",
    "# transcript_sentences = nltk.sent_tokenize(transcript)\n",
    "# tokenized_sentences = []\n",
    "# for sentence in transcript_sentences:\n",
    "#     tokenized_sentence = tokenizer(sentence, return_tensors=\"pt\")\n",
    "#     tokenized_sentences.append(tokenized_sentence)\n",
    "\n",
    "# translation = []\n",
    "# for sentence in tokenized_sentences:\n",
    "#     input = {\"input_ids\": sentence[\"input_ids\"][0].unsqueeze(0)}\n",
    "#     output = mt_model.generate(**input)\n",
    "#     translation.append(tokenizer.decode(output[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvMT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
