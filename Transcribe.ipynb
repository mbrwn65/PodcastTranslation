{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if not \"venv\" in sys.executable:\n",
    "    raise EnvironmentError(\"The script must be run in a virtual environment with ipykernel installed\")\n",
    "\n",
    "user_input = input(\"(y/n) Would you like to uninstall all existing packages and install the necessary requirements from startingreqs.txt?\")\n",
    "\n",
    "if user_input.lower() == \"y\":\n",
    "    #saves current packages to uninstall.txt\n",
    "    !pip3 freeze > uninstall.txt\n",
    "    #uninstalls all non-essential packages in environment\n",
    "    !pip3 uninstall -r uninstall.txt -y\n",
    "    #installs necessary packages\n",
    "    !pip3 install -r startingreqs.txt\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "import ctranslate2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Podcasts/podcastsegmentfr.mp3\n"
     ]
    }
   ],
   "source": [
    "podcastfolder = \"./Podcasts\"\n",
    "podcastfiles = []\n",
    "for file in os.listdir(podcastfolder):\n",
    "    if file != \".DS_Store\":\n",
    "        podcastfiles.append(file)\n",
    "podcastaudio = podcastfolder + \"/\" + podcastfiles[0]\n",
    "print(podcastaudio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Whisper Turbo Model to CT2 with Int8 Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BELOW IS CODE USED TO CONVERT TURBO WHISPER MODEL TO CT2 INT8 QUANTIZED MODEL (STORED AT huggingface Mbwn/whisper-turbo-ct2)\n",
    "# turbo_model = \"openai/whisper-large-v3-turbo\"\n",
    "# ct2_output_dir = \"whisper-large-v3-turbo-ct2\"\n",
    "\n",
    "# converter = ctranslate2.converters.TransformersConverter(\n",
    "#     model_name_or_path=turbo_model, copy_files=[\"tokenizer.json\", \"preprocessor_config.json\"]\n",
    "# )\n",
    "# converter.convert(output_dir=ct2_output_dir, quantization=\"int8\", force=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Turbo Model With Int8 Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Mbrwn/whisper-turbo-ct2\"\n",
    "model = WhisperModel(model_name, device = \"cpu\", compute_type=\"int8\")\n",
    "segments, info = model.transcribe(podcastaudio, beam_size=5, language=\"fr\")\n",
    "transcript = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s -> 8.54s]  sa capacité à fédérer, c'est-à-dire à faire en sorte que la population se réunisse et soit heureuse ensemble.\n",
      "[9.34s -> 16.08s]  La France a aussi pu montrer, grâce aux Jeux olympiques, sa capacité à construire des infrastructures,\n",
      "[16.08s -> 25.32s]  donc des bâtiments de qualité, à accueillir le tourisme et à organiser en général un des événements les plus importants du monde.\n",
      "[25.60s -> 28.46s]  Voilà, donc ça c'est pour la partie un peu logistique.\n",
      "[28.46s -> 33.50s]  Et maintenant, si on s'intéresse plus particulièrement aux performances sportives,\n",
      "[34.22s -> 37.52s]  la France avait un objectif assez clair pour ces Jeux olympiques.\n",
      "[38.00s -> 43.72s]  On voulait faire partie du top 5 des nations au classement des médailles.\n",
      "[43.72s -> 52.84s]  Autrement dit, être dans les 5 premiers pays en ce qui concerne le nombre de médailles et plus particulièrement les médailles d'or.\n",
      "[52.84s -> 59.12s]  Et Cocorico, on a réussi, puisque la France a remporté 64.\n"
     ]
    }
   ],
   "source": [
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "    transcript.append(segment.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvMT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
